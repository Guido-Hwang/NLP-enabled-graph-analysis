{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 计算每天的情感倾向,作为边的权重\n",
    "# 每个人可能有很多条评论,结果相加"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "file_names = os.listdir(os.getcwd())  # 路径\n",
    "comment_file = (re.findall('user_L[0-9]+_post_comment.csv', ''.join(file_names)))\n",
    "print(len(comment_file))\n",
    "data=pd.DataFrame()\n",
    "for file in comment_file:\n",
    "    data =data.append(pd.read_csv(file, encoding='utf_8_sig'))\n",
    "\n",
    "data['content'].replace(to_replace=' ',value='',inplace=True)\n",
    "data.dropna(subset=['content'],inplace=True)\n",
    "data['sentiment']=None\n",
    "data['score']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_user_name, post_id, reply2user, content, date, sentiment, score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 去除自己的回复自己的\n",
    "# data[data['author_user_name']==data['reply1user']]\n",
    "data.drop(data[data['author_user_name']==data['reply2user']].index,inplace=True)\n",
    "print(data[data['author_user_name']==data['reply2user']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20756it [01:43, 201.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for index,row in tqdm(data.iterrows()):\n",
    "    data.at[index,'score']=SnowNLP(row['content']).sentiments\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data.loc[data['score']>=0.7,'sentiment']=1\n",
    "data.loc[data[(0.3<data['score'])&(data['score']<0.7)].index,'sentiment']=0\n",
    "data.loc[data['score']<=0.3,'sentiment']=-1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 计算周围节点 对该节点的评价求和\n",
    "# 计算每个节点 对该节点的评价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [01:07<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16185.000000\n",
      "mean         0.177263\n",
      "std          9.080911\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max       1128.000000\n",
      "Name: sentiment_sum, dtype: float64\n",
      "count    18276.000000\n",
      "mean         0.027577\n",
      "std          0.724558\n",
      "min         -1.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: sentiment_classify, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "node=pd.read_csv(f\"node.csv\", encoding='utf_8_sig')\n",
    "edge=pd.read_csv(f\"edge.csv\", encoding='utf_8_sig')\n",
    "node['sentiment_sum']=0\n",
    "node['sentiment_category']=0 # 取绝对值然后分类,为了方便可视化\n",
    "edge['sentiment_classify']=0 # 求和之后 进行分类 -1 0\n",
    "for name,group in tqdm(data.groupby('reply2user')):\n",
    "    # print(name,group['sentiment'].sum())\n",
    "    index= node['author_user_name']==name\n",
    "    sentiment_sum=group['sentiment'].sum()\n",
    "    if sentiment_sum>0:\n",
    "        node.at[index,'sentiment_category']=1\n",
    "    elif sentiment_sum<0:\n",
    "        node.at[index,'sentiment_category']=-1\n",
    "    else:\n",
    "        node.at[index,'sentiment_category']=0\n",
    "    node.at[index,'sentiment_sum']=abs(sentiment_sum)\n",
    "\n",
    "    for n,g in group.groupby('author_user_name'):\n",
    "        edge.loc[edge[(edge['author_user_name']==str(n))&(edge['reply2user']==str(name))].index,'sentiment_classify']=g['sentiment'].sum()\n",
    "    # break\n",
    "edge.loc[edge['sentiment_classify']>0,'sentiment_classify']=1\n",
    "edge.loc[edge['sentiment_classify']==0,'sentiment_classify']=0\n",
    "edge.loc[edge['sentiment_classify']<0,'sentiment_classify']=-1\n",
    "print(node['sentiment_sum'].describe())\n",
    "print(edge['sentiment_classify'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 将观点求总"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [00:00<00:00, 449.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "post_file = (re.findall('user_L[0-9]+_post_filter.csv', ''.join(file_names)))\n",
    "print(len(post_file))\n",
    "post=pd.DataFrame()\n",
    "for file in post_file:\n",
    "    post =post.append(pd.read_csv(file, encoding='utf_8_sig'))\n",
    "\n",
    "node['prop_adj_list']=None\n",
    "for name,group in tqdm(post.groupby('author_user_name')):\n",
    "    tmp=[]\n",
    "    for index,row in group.iterrows():\n",
    "        tmp.extend(literal_eval(row['prop_adj_list']))\n",
    "    tmp=list(set(tmp))\n",
    "    node.at[node[node['author_user_name']==str(name)].index[0],'prop_adj_list']=tmp\n",
    "    # print(name,group['sentiment'].sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# save\n",
    "node.to_csv('node.csv',index=False,encoding='utf_8_sig')\n",
    "edge.to_csv('edge.csv',index=False,encoding='utf_8_sig')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}